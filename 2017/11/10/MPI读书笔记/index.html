<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> MPI读书笔记(一) · yangsoon</title><meta name="description" content="MPI读书笔记(一) - yangs"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://yangsoon.github.io/atom.xml" title="yangsoon"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/yangsoon" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="https://www.zhihu.com/people/song-yang-91-69/activities" target="_blank" class="nav-list-link">ZHIHU</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">MPI读书笔记(一)</h1><div class="post-info">2017年11月10日</div><div class="post-content"><h2 id="序"><a href="#序" class="headerlink" title="序"></a>序</h2><p>确认研究方向是并行计算之后，却一直没有认真接触。从开学到现在这段时间都在看一些无关紧要的东西，像<a href="https://cn.vuejs.org/" target="_blank" rel="noopener">vuejs</a>把官方文档过了一遍；<a href="https://book.douban.com/subject/27028517/" target="_blank" rel="noopener">《流畅的python》</a>也看了一多半，感觉确实写的很nice；接触了python web异步框架<a href="https://tornado-zh.readthedocs.io/zh/latest/#" target="_blank" rel="noopener">tornado</a>。最近用vue全家桶(<a href="https://cn.vuejs.org/" target="_blank" rel="noopener">vuejs</a>、<a href="https://router.vuejs.org/zh-cn/" target="_blank" rel="noopener">vue-router</a>、<a href="https://vuex.vuejs.org/zh-cn/" target="_blank" rel="noopener">vuex</a>)和<a href="https://tornado-zh.readthedocs.io/zh/latest/#" target="_blank" rel="noopener">tornado</a>写了一些东西，关于这部分准备以后写篇文章来记录下。近期要开始毕设选题了，北航的学长帮我想了一个和并行计算相关的课题。也推荐了<a href="https://book.douban.com/subject/1244566/" target="_blank" rel="noopener">《高性能计算-并行编程技术》</a>当做入门书籍。这篇文章就当一个学习笔记，记录mpi一些相关的知识点。后期准备将每个章节出现的代码都用c重新实现一遍。<a href="https://github.com/yangsoon/MPI-Demo" target="_blank" rel="noopener">相关代码地址</a><br><a id="more"></a></p>
<h1 id="并行计算基础"><a href="#并行计算基础" class="headerlink" title="并行计算基础"></a>并行计算基础</h1><h2 id="第1章-并行计算机"><a href="#第1章-并行计算机" class="headerlink" title="第1章-并行计算机"></a>第1章-并行计算机</h2><p>并行计算机即在同一时间执行多条指令(或处理多个数据)的计算机，并行计算机是并行计算的物理载体。</p>
<ul>
<li>根据并行计算机能同时执行指令和数据的多少分为 SIMD(单指令多数据)和MIMD(多指令多数据)</li>
<li>根据执行程序和数据的不同分为SPMD(单程序多数据)和MPMD(多程序多数据)</li>
<li>从存储方式上可以分为共享内存、分布式内存、分布式共享内存并行计算机</li>
</ul>
<h2 id="第2章-并行编程模行与并行语言-amp-amp-第3章-并行算法"><a href="#第2章-并行编程模行与并行语言-amp-amp-第3章-并行算法" class="headerlink" title="第2章-并行编程模行与并行语言&amp;&amp;第3章-并行算法"></a>第2章-并行编程模行与并行语言&amp;&amp;第3章-并行算法</h2><h1 id="基本MPI程序设计"><a href="#基本MPI程序设计" class="headerlink" title="基本MPI程序设计"></a>基本MPI程序设计</h1><h2 id="第4章-MPI简介"><a href="#第4章-MPI简介" class="headerlink" title="第4章-MPI简介"></a>第4章-MPI简介</h2><p>1.MPI是一个库，而不是一门语言。<br>2.MPI是一种规范或标准的代表，不特指某一个对它的具体实现。<br>3.MPI是一种消息传递编程模型。</p>
<h2 id="第5章-第一个MPI程序"><a href="#第5章-第一个MPI程序" class="headerlink" title="第5章-第一个MPI程序"></a>第5章-第一个MPI程序</h2><p>下面演示第一个mpi程序的编写和运行结果。后面解释mpi的api。</p>
<blockquote>
<p><code>hello.c</code></p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> myid, numprocs;</span><br><span class="line">	<span class="keyword">int</span> namelen;</span><br><span class="line">	<span class="keyword">char</span> processor_name[MPI_MAX_PROCESSOR_NAME];</span><br><span class="line"></span><br><span class="line">	MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">	MPI_Comm_rank(MPI_COMM_WORLD, &amp;myid);</span><br><span class="line">	MPI_Comm_size(MPI_COMM_WORLD, &amp;numprocs);</span><br><span class="line">	MPI_Get_processor_name(processor_name, &amp;namelen);</span><br><span class="line"></span><br><span class="line">	<span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"Hello World! Process %d of %d on %s\n"</span>, myid, numprocs, processor_name);</span><br><span class="line"></span><br><span class="line">	MPI_Finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行</p>
<blockquote>
<p><code>mpicc -o hello hello.c</code><br><code>mpirun -n 2 hello</code>(跑在本地2核处理器见谅见谅)</p>
</blockquote>
<p>结果</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Hello World! Process 1 of 2 on promote.cache-dns.local</span><br><span class="line">Hello World! Process 0 of 2 on promote.cache-dns.local</span><br></pre></td></tr></table></figure>
<h2 id="第6章-六个接口构成的MPI子集"><a href="#第6章-六个接口构成的MPI子集" class="headerlink" title="第6章-六个接口构成的MPI子集"></a>第6章-六个接口构成的MPI子集</h2><h4 id="子集介绍"><a href="#子集介绍" class="headerlink" title="子集介绍"></a>子集介绍</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">初始化mpi</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Init</span><span class="params">(<span class="keyword">int</span> *argc, <span class="keyword">char</span>***argv)</span></span></span><br><span class="line">MPI结束 </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Finalize</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line">当前进程标识 </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_rank</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *rank)</span></span></span><br><span class="line">通信域包含的进程数  </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_size</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *size)</span></span></span><br><span class="line">消息发送 </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Send</span><span class="params">(<span class="keyword">void</span>* buff, <span class="keyword">int</span> count, MPI_Datatype datatype, <span class="keyword">int</span> dest, <span class="keyword">int</span> tag, MPI_Comm comm)</span></span></span><br><span class="line">消息接收 </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Recv</span><span class="params">(<span class="keyword">void</span>* buff, <span class="keyword">int</span> count, MPI_Datatype datatype, <span class="keyword">int</span> source, <span class="keyword">int</span> tag, MPI_Comm comm, MPI_Status *status)</span></span></span><br></pre></td></tr></table></figure>
<h4 id="参数介绍"><a href="#参数介绍" class="headerlink" title="参数介绍"></a>参数介绍</h4><blockquote>
<p><code>MPI_Comm_rank</code></p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_Comm comm 			该进程所在的通信域(句柄)</span><br><span class="line"><span class="keyword">int</span> *rank     			调用进程在comm中的标识号</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>int MPI_Comm_size</code></p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> *size     通信域comm内包含的进程数</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>MPI_Send</code></p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span>* buf                  				发送缓冲区的起始地址(可选类型)</span><br><span class="line"><span class="keyword">int</span> count                  				将发送的数据个数(非负整数)</span><br><span class="line">MPI_Datatype datatype      				发送数据的数据类型(句柄)</span><br><span class="line"><span class="keyword">int</span> dest                   				目的进程的标识号(整型)</span><br><span class="line"><span class="keyword">int</span> tag                    				消息标志(整型)</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>MPI_Recv</code></p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span>* buf                  				接收缓冲区的起始地址(可选类型)</span><br><span class="line"><span class="keyword">int</span> count                  				最多可接受的数据个数(非负整数)</span><br><span class="line">MPI_Datatype datatype      				接收数据的数据类型(句柄)</span><br><span class="line"><span class="keyword">int</span> dest                   				接收数据来源进程的标识号(整型)</span><br><span class="line"><span class="keyword">int</span> tag                    				消息标志(整型)</span><br><span class="line"><span class="keyword">int</span> *status                				返回状态(状态类型)</span><br><span class="line">MPI_Status status &#123; MPI_SOURCE, MPI_TAG, MPI_ERROR &#125;</span><br></pre></td></tr></table></figure>
<h4 id="一个简单的接收和发送的例子"><a href="#一个简单的接收和发送的例子" class="headerlink" title="一个简单的接收和发送的例子"></a>一个简单的接收和发送的例子</h4><blockquote>
<p><code>example1.c</code></p>
</blockquote>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 参照原书6.1.9部分代码，略有改动。</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> message[<span class="number">20</span>];</span><br><span class="line">    <span class="keyword">int</span> myrank;</span><br><span class="line">    <span class="keyword">int</span> number;</span><br><span class="line">    MPI_Status status;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// MPI程序初始化</span></span><br><span class="line">    MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">    <span class="comment">// 得到当前进程的标识</span></span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;myrank);</span><br><span class="line">    <span class="comment">// 得到通信域下的进程数</span></span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;number);</span><br><span class="line">    <span class="comment">// 进程0发送消息给进程1</span></span><br><span class="line">    <span class="keyword">if</span> (myrank == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"mpi size:%d\n"</span>, number);</span><br><span class="line">        <span class="built_in">strcpy</span>(message, <span class="string">"Hello,process 1"</span>);</span><br><span class="line">        MPI_Send(message, <span class="built_in">strlen</span>(message), MPI_CHAR, <span class="number">1</span>, <span class="number">99</span>, MPI_COMM_WORLD);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"process%d send: %s -&gt; process 1\n"</span>, myrank, message);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 进程1接收来自进程0的消息</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(myrank == <span class="number">1</span>) &#123;</span><br><span class="line">        MPI_Recv(message, <span class="number">20</span>, MPI_CHAR, <span class="number">0</span>, <span class="number">99</span>, MPI_COMM_WORLD, &amp;status);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"process%d recived: %s &lt;- process 0\n"</span> ,myrank ,message);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"status-&gt;MPI_SOURCE:%d\n"</span>, status.MPI_SOURCE);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"status-&gt;MPI_TAG:%d\n"</span>, status.MPI_TAG);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"status-&gt;MPI_ERROR:%d\n"</span>, status.MPI_ERROR);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 结束</span></span><br><span class="line">    MPI_Finalize();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mpi size:2</span><br><span class="line">process0 send: Hello,process 1 -&gt; process 1</span><br><span class="line">process1 recived: Hello,process 1 &lt;- process 0</span><br><span class="line">status-&gt;MPI_SOURCE:0</span><br><span class="line">status-&gt;MPI_TAG:99</span><br><span class="line">status-&gt;MPI_ERROR:0</span><br></pre></td></tr></table></figure></p>
<h4 id="mpi预定义数据类型"><a href="#mpi预定义数据类型" class="headerlink" title="mpi预定义数据类型"></a>mpi预定义数据类型</h4><table>
<thead>
<tr>
<th style="text-align:center">MPI预定义数据类型</th>
<th style="text-align:center">相应的c数据类型</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">MPI_CHAR</td>
<td style="text-align:center">signed char</td>
</tr>
<tr>
<td style="text-align:center">MPI_SHORT</td>
<td style="text-align:center">signed short int</td>
</tr>
<tr>
<td style="text-align:center">MPI_INT</td>
<td style="text-align:center">signed int</td>
</tr>
<tr>
<td style="text-align:center">MPI_LONG</td>
<td style="text-align:center">signed long int</td>
</tr>
<tr>
<td style="text-align:center">MPI_UNSIGNED_CHAR</td>
<td style="text-align:center">unsigned char</td>
</tr>
<tr>
<td style="text-align:center">MPI_UNSIGNED_SHORT</td>
<td style="text-align:center">unsigned short int</td>
</tr>
<tr>
<td style="text-align:center">MPI_UNSIGNED</td>
<td style="text-align:center">unsigned int</td>
</tr>
<tr>
<td style="text-align:center">MPI_UNSIGNED_LONG</td>
<td style="text-align:center">unsigned long int</td>
</tr>
<tr>
<td style="text-align:center">MPI_FLOAT</td>
<td style="text-align:center">float</td>
</tr>
<tr>
<td style="text-align:center">MPI_DOUBLE</td>
<td style="text-align:center">double</td>
</tr>
<tr>
<td style="text-align:center">MPI_LONG_DOUBLE</td>
<td style="text-align:center">long double</td>
</tr>
<tr>
<td style="text-align:center">MPI_BYTE</td>
<td style="text-align:center">#</td>
</tr>
<tr>
<td style="text-align:center">MPI_PACKED</td>
<td style="text-align:center">#</td>
</tr>
</tbody>
</table>
<h4 id="mpi消息组成"><a href="#mpi消息组成" class="headerlink" title="mpi消息组成"></a>mpi消息组成</h4><p><img src="http://ww1.sinaimg.cn/large/006r0i4lgy1fle2ogr9tej30t40feabl.jpg" style="width:400px;"></p>
<h2 id="第7章-简单的MPI程序示例"><a href="#第7章-简单的MPI程序示例" class="headerlink" title="第7章-简单的MPI程序示例"></a>第7章-简单的MPI程序示例</h2><div class="tip"><br>书中此部分有7个demo，但由于实验环境问题，有些代码不能很好的调试，后面我会不断完善这部分的代码，<a href="https://github.com/yangsoon/MPI-Demo" target="_blank" rel="noopener">代码地址</a>托管在github上。请大家见谅！<br></div>

<h2 id="第8章-MPI并行计算的两种基本模式"><a href="#第8章-MPI并行计算的两种基本模式" class="headerlink" title="第8章-MPI并行计算的两种基本模式"></a>第8章-MPI并行计算的两种基本模式</h2><p>mpi的两种基本模式：对等模式和主从模式，绝大多数MPI程序都是这两种模式之一或二</p>
<h4 id="对等模式的MPI程序设计"><a href="#对等模式的MPI程序设计" class="headerlink" title="对等模式的MPI程序设计"></a>对等模式的MPI程序设计</h4><blockquote>
<p>在这里采用了Jacobi迭代举例子，Jacobi迭代就是迭代的新值是原来的旧值点相邻数值点的平均，将参与迭代的数据安快分割后，个快之间除了相邻的元素需要通信外，在个快的内部可以完全独立地并行计算，随着计算规模的扩大，通信的开销相对于计算来说比例会降低，这将更有利于提高并行效果。</p>
</blockquote>
<p>为了并行求解，这里将参加迭代的数据按列进行分割，并假设一共有4个进程同时并行计算，数据的分割结果如图所示。<br><img src="http://ww1.sinaimg.cn/large/006r0i4lgy1fle3nnlgvoj31ai0o2n0f.jpg"></p>
<blockquote>
<p>由于在迭代过程中，边界点新值的计算需要相邻边界其它块的数据，因此在每个数据块的两侧又各增加1列的数据空间，用于存放从相邻数据块通信得到的数据。这样原来每个数据块的大小从M*N扩大到M* (N+2),进程0和进程1的数据块只需扩大一块即可满足通信的要求，但这里为了编程的方便和形式的一致，在两边都增加了数据块。计算和通信过程是这样的，首先对数组赋初值，边界赋为8，内部赋为0，注意对不同的进程，赋值方式是不同的(两个内部块相同，但内部块和两个外部块两两互不相同)。然后便开始进行Jacobi迭代，在迭代之前，每个进程都需要从相邻的进程得到数据块，同时每一个进程也都需要向相邻的进程提供数据块(图27,注意FORTRAN数组在内存中是按列优先排列的)。由于每一个新迭代点的值是由相邻点的旧值得到，所以这里弓|入一个中间数组，用来记录临时得到的新值，一次迭代完成后，再统一进行更新操作。</p>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/006r0i4lgy1fle3vebmtgj316q0rwgpj.jpg"></p>
<h4 id="矩阵向量乘法-主从模式"><a href="#矩阵向量乘法-主从模式" class="headerlink" title="矩阵向量乘法-主从模式"></a>矩阵向量乘法-主从模式</h4><blockquote>
<p>下面的例子实现C=AxB。主进程将向量B广播给所有的从进程，然后将矩阵A的各行依次发送给从进程，从进程计算一行和B相乘的结果，然后将结果发送给主进程。主进程循环向各个从进程发送一行的数据，直到将A各行的数据发送完毕,一旦主进程将A的各行发送完毕，则每收到一个结果，就向相应的从进程发送结束标志，从进程接收到结束标志后退出执行。主进程收集完所有的结果后也结束。</p>
</blockquote>
<p><img src="http://ww1.sinaimg.cn/large/006r0i4lgy1fle3yu01naj316u0nc41f.jpg"></p>
<div class="tip">第九章内容太多，放在一篇文章里太长了，所以就放到了下一篇文章里，以上部分是mpi的一些基础部分，后面就开始讲解高级的并行计算。</div></div></article></div></main><footer><div class="paginator"><a href="/2017/11/21/telegram-bots-for-developers/" class="prev">上一篇</a><a href="/2017/10/01/vagrant开发遇到的坑/" class="next">下一篇</a></div><div id="container"></div><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script><script>var gitment = new Gitment({
    id: 'Fri Nov 10 2017 14:55:15 GMT+0800',
    owner: 'yangsoon',
    repo: 'yangsoon.github.io',
    oauth: {
        client_id: 'c6e81705ee274d631d1d',
        client_secret: 'd2366443245bc5528fc5a73af235d9e23d14e33a',
    },
})
gitment.render('container')</script><div class="copyright"><p>© 2015 - 2018 <a href="https://yangsoon.github.io">yangs</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><!-- - LaTex--><script type="text/x-mathjax-config">MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});</script><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-117274875-1",'auto');ga('send','pageview');</script></body></html>